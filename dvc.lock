schema: '2.0'
stages:
  build-tokenizer:
    cmd: python scripts/train_tokenizer.py --vocab-size 30000
    deps:
    - path: scripts/train_tokenizer.py
      md5: 64679f06ed52243ae739cf309d8279c6
      size: 3215
    outs:
    - path: data/tokenizer
      md5: 46c9ecb5c7cc3fa7699eb3c3f07c027f.dir
      size: 1656261
      nfiles: 2
